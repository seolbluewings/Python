{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토픽의 개수를 미리 결정(T=4) 하고\n",
    "- 문서(documents) 에 대한 데이터 부여, 원래는 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [[\"은행\", \"플랫폼\", \"이자\", \"비이자\", \"Valuation\", \"성장성\", \"주가\", \"대출\"], \n",
    "    [\"자동차\", \"반도체\", \"성장성\", \"자율주행\",\"당기순이익\",\"칩\"],\n",
    "    [\"CMO\", \"바이오\", \"코로나\", \"백신\", \"공정\", \"매출액\", \"성장성\", \"모더나\", \"바이러스\"],\n",
    "    [\"실적\", \"이자\", \"비은행\", \"은행\", \"대출\", \"증권\",\"비이자\"],\n",
    "    [\"바이오시밀러\", \"코로나\", \"바이러스\", \"백신\", \"수익성\", \"바이오\"],\n",
    "    [\"5G\", \"이동통신\", \"매출\", \"이익\", \"커머스\", \"지주\"],\n",
    "    [\"스마트팩토리\", \"수익률\", \"통신\", \"IPTV\"],\n",
    "    [\"GDP\", \"운용자산\", \"M&A\", \"코로나\", \"금리\", \"중앙은행\"],\n",
    "    [\"IPTV\", \"턴어라운드\", \"5G\", \"이익\", \"인터넷\", \"통신\"],\n",
    "    [\"반도체\", \"인공지능\", \"IP\", \"플랫폼\", \"칩\", \"자율주행\"],\n",
    "    [\"원자현미경\", \"공정\", \"반도체\", \"성장\", \"수익성\", \"디스플레이\"],\n",
    "    [\"로보택시\", \"모빌리티\", \"자율주행\", \"라이다\", \"자동차\"],\n",
    "    [\"임상\", \"백신\", \"식약처\", \"3상\", \"결과발표\", \"모멘텀\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $I(z_{n}^{(d)}=t)$ : document_topic_counts\n",
    "- $\\sum_{d=1}^{D}\\sum_{n=1}^{N_{d}}I(w_{n}^{(d)}=m)I(z_{n}^{(d)}=t)$ : topic_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topic_counts = [Counter() for _ in documents]\n",
    "\n",
    "topic_word_counts = [Counter() for _ in range(T)]\n",
    "\n",
    "topic_counts = [0 for _ in range(T)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 문서(d)에 존재하는 단어의 개수 $N_{d}$ 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_lengths = list(map(len, documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 문서의 개수 $(D)$ 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터에 존재하는 전체 단어의 Unique 개수 $(M)$ 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = list()\n",
    "for d in range(D):\n",
    "    N_d = list(map(len, documents))[d]\n",
    "    for n in range(N_d):\n",
    "        word_vec.append(documents[d][n])\n",
    "\n",
    "unique_word_vec = set(word_vec)\n",
    "M = len(unique_word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word_vec = set(word_vec)\n",
    "M = len(unique_word_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gibbs Sampling Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gibbs Sampling 실행 과정에서 사용하게 될 conditional distribution 에 대한 코드 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ p(z_{n}^{(d)}=t \\vert z_{-n}^{(d)},\\mathbf{w},\\alpha,\\beta) \\propto \\frac{ \\beta_{m}+\\sum_{d=1}^{D}\\sum_{n=1}^{N_{d}}I(w_{n}^{(d)}=m)I(z_{n}^{(d)}=t)}{ \\sum_{m=1}^{M}\\left(\\beta_{m}+\\sum_{d=1}^{D}\\sum_{n=1}^{N_{d}}I(w_{n}^{(d)}=m)I(z_{n}^{(d)}=t) \\right) } \\times \\left( \\alpha_{t}+ \\sum_{n=1}^{N_{d}} I(z_{n}^{(d)}=t) \\right) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_weight(d, word, topic):\n",
    "    \n",
    "    alpha = 1/T\n",
    "    beta  = 1/M\n",
    "    \n",
    "    return (document_topic_counts[d][topic]+alpha)*((topic_word_counts[topic][word]+beta)/(topic_counts[topic]+M*beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_new_topic(d, word) :\n",
    "    weights = np.zeros(T)\n",
    "    for topic in range(T) :\n",
    "        weights[topic] = topic_weight(d, word, topic) \n",
    "    \n",
    "    total = weights.sum()\n",
    "    t = np.argmax(np.random.multinomial(1, pvals = weights/total))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문서에 존재하는 각 단어들에 대해 토픽 할당\n",
    "- Gibbs Sampling 수행을 위해 각 단어에 대해 토픽 최초값을 임의로 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 0, 3, 1, 3, 1, 1, 2],\n",
       " [1, 1, 2, 0, 1, 2],\n",
       " [3, 0, 0, 3, 3, 0, 1, 1, 0],\n",
       " [1, 0, 2, 0, 0, 0, 2],\n",
       " [2, 1, 3, 0, 1, 1],\n",
       " [2, 1, 0, 1, 2, 2],\n",
       " [3, 2, 0, 2],\n",
       " [0, 1, 2, 1, 1, 0],\n",
       " [3, 1, 3, 0, 3, 2],\n",
       " [1, 1, 1, 1, 0, 3],\n",
       " [1, 2, 0, 1, 0, 2],\n",
       " [1, 3, 2, 2, 3],\n",
       " [2, 2, 0, 0, 2, 3]]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topics = [[random.randrange(T) for word in document] for document in documents]\n",
    "document_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zip은 두 개의 list의 값을 병렬 추출\n",
    "- 두 개의 list가 있을 때 각 인덱스에 있는 값들을 뽑아주는 것이 zip\n",
    "- 문서에 대해 for문을 돌리면서 개수를 Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] = document_topic_counts[d][topic] + 1 \n",
    "        topic_word_counts[topic][word] = topic_word_counts[topic][word] + 1\n",
    "        topic_counts[topic] = topic_counts[topic] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({2: 2, 0: 1, 3: 2, 1: 3}),\n",
       " Counter({1: 3, 2: 2, 0: 1}),\n",
       " Counter({3: 3, 0: 4, 1: 2}),\n",
       " Counter({1: 1, 0: 4, 2: 2}),\n",
       " Counter({2: 1, 1: 3, 3: 1, 0: 1}),\n",
       " Counter({2: 3, 1: 2, 0: 1}),\n",
       " Counter({3: 1, 2: 2, 0: 1}),\n",
       " Counter({0: 2, 1: 3, 2: 1}),\n",
       " Counter({3: 3, 1: 1, 0: 1, 2: 1}),\n",
       " Counter({1: 4, 0: 1, 3: 1}),\n",
       " Counter({1: 2, 2: 2, 0: 2}),\n",
       " Counter({1: 1, 3: 2, 2: 2}),\n",
       " Counter({2: 3, 0: 2, 3: 1})]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100): # repetition\n",
    "    for d in range(D): # each documnet\n",
    "        for i, (word, topic) in enumerate(zip(documents[d],document_topics[d])):\n",
    "            \n",
    "            # gibbs sampling: 특정 하나의 topic assignment z를 제거하고 나머지들(-z)의 조건부 확률  \n",
    "            \n",
    "            # remove this word / topic from the counts\n",
    "            # so that it doesn't influence the weights\n",
    "            document_topic_counts[d][topic] -= 1 # 문서별 토픽 갯수\n",
    "            topic_word_counts[topic][word] -= 1 # 토픽별 단어 갯수\n",
    "            topic_counts[topic] -= 1 # 토픽별 카운트\n",
    "            document_lengths[d] -= 1 # 문서별 단어갯수\n",
    "            \n",
    "            # choose a new topic based on the weights\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "            \n",
    "            # and now add it back to the counts\n",
    "            document_topic_counts[d][new_topic] += 1 # 문서별 토픽 갯수\n",
    "            topic_word_counts[new_topic][word] += 1 # 토픽별 단어 갯수\n",
    "            topic_counts[new_topic] += 1 # 토픽별 카운트\n",
    "            document_lengths[d] += 1 # 문서별 단어갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Topic1','Topic2','Topic3','Topic4'], index=['Top'+str(i) for i in range(1,6)])\n",
    "\n",
    "for k, word_counts in enumerate(topic_word_counts):\n",
    "    for ix, (word, count) in enumerate(word_counts.most_common(6)): # 각 토픽별로 top 10 단어\n",
    "            df.loc['Top'+str(ix+1),'Topic'+str(k+1)] = word+'({})'.format(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Top1</th>\n",
       "      <td>이자(2)</td>\n",
       "      <td>성장성(3)</td>\n",
       "      <td>백신(3)</td>\n",
       "      <td>IPTV(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top2</th>\n",
       "      <td>은행(2)</td>\n",
       "      <td>반도체(3)</td>\n",
       "      <td>코로나(3)</td>\n",
       "      <td>5G(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top3</th>\n",
       "      <td>대출(2)</td>\n",
       "      <td>자율주행(3)</td>\n",
       "      <td>바이오(2)</td>\n",
       "      <td>이익(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top4</th>\n",
       "      <td>비이자(2)</td>\n",
       "      <td>자동차(2)</td>\n",
       "      <td>수익성(2)</td>\n",
       "      <td>통신(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top5</th>\n",
       "      <td>증권(1)</td>\n",
       "      <td>플랫폼(2)</td>\n",
       "      <td>바이러스(2)</td>\n",
       "      <td>스마트팩토리(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top6</th>\n",
       "      <td>Valuation(1)</td>\n",
       "      <td>공정(2)</td>\n",
       "      <td>바이오시밀러(1)</td>\n",
       "      <td>인터넷(1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Topic1   Topic2     Topic3     Topic4\n",
       "Top1         이자(2)   성장성(3)      백신(3)    IPTV(2)\n",
       "Top2         은행(2)   반도체(3)     코로나(3)      5G(2)\n",
       "Top3         대출(2)  자율주행(3)     바이오(2)      이익(2)\n",
       "Top4        비이자(2)   자동차(2)     수익성(2)      통신(2)\n",
       "Top5         증권(1)   플랫폼(2)    바이러스(2)  스마트팩토리(1)\n",
       "Top6  Valuation(1)    공정(2)  바이오시밀러(1)     인터넷(1)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
