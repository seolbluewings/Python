{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토픽의 개수를 미리 결정(T=4) 하고\n",
    "- 문서(documents) 에 대한 데이터 부여, 원래는 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [[\"은행\", \"플랫폼\", \"이자\", \"비이자\", \"Valuation\", \"성장성\", \"주가\", \"대출\"], \n",
    "    [\"자동차\", \"반도체\", \"성장성\", \"자율주행\",\"당기순이익\",\"칩\"],\n",
    "    [\"CMO\", \"바이오\", \"코로나\", \"백신\", \"공정\", \"매출액\", \"성장성\", \"모더나\", \"바이러스\"],\n",
    "    [\"실적\", \"이자\", \"비은행\", \"은행\", \"대출\", \"증권\",\"비이자\"],\n",
    "    [\"바이오시밀러\", \"코로나\", \"바이러스\", \"백신\", \"수익성\", \"바이오\"],\n",
    "    [\"5G\", \"이동통신\", \"매출\", \"이익\", \"커머스\", \"지주\"],\n",
    "    [\"스마트팩토리\", \"수익률\", \"통신\", \"5G\", \"IPTV\"],\n",
    "    [\"IPTV\", \"턴어라운드\", \"5G\", \"이익\", \"인터넷\", \"통신\"],\n",
    "    [\"반도체\", \"인공지능\", \"IP\", \"플랫폼\", \"칩\", \"자율주행\"],\n",
    "    [\"원자현미경\", \"공정\", \"반도체\", \"성장\", \"수익성\", \"디스플레이\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 데이터 개수를 count하기 위한 Counter() 함수 사용\n",
    "- 인덱스를 무시하고 각 문서(document) 별로 Counter() 생성\n",
    "- 각 문서(Document) 별로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of Counters, one for each document\n",
    "document_topic_counts = [Counter() for _ in documents]\n",
    "\n",
    "# a list of Counters, one for each topic\n",
    "topic_word_counts = [Counter() for _ in range(T)]\n",
    "\n",
    "# a list of numbers, one for each topic\n",
    "topic_counts = [0 for _ in range(T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({3: 3, 1: 0, 2: 5, 0: 0}),\n",
       " Counter({3: 6, 2: 0, 0: 0, 1: 0}),\n",
       " Counter({3: 0, 1: 9, 0: 0, 2: 0}),\n",
       " Counter({2: 7, 3: 0, 0: 0, 1: 0}),\n",
       " Counter({1: 5, 2: 0, 0: 0, 3: 1}),\n",
       " Counter({3: 0, 0: 6, 2: 0, 1: 0}),\n",
       " Counter({0: 5, 1: 0, 2: 0, 3: 0}),\n",
       " Counter({1: 0, 3: 0, 0: 6, 2: 0}),\n",
       " Counter({3: 6, 0: 0, 2: 0, 1: 0}),\n",
       " Counter({0: 0, 3: 0, 2: 0, 1: 6})]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 문서(d)에 존재하는 단어의 개수 $N_{d}$ 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_lengths = list(map(len, documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 문서의 개수 $(D)$ 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터에 존재하는 전체 단어의 Unique 개수 $(M)$ 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = list()\n",
    "for d in range(D):\n",
    "    N_d = list(map(len, documents))[d]\n",
    "    for n in range(N_d):\n",
    "        word_vec.append(documents[d][n])\n",
    "\n",
    "unique_word_vec = set(word_vec)\n",
    "M = len(unique_word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word_vec = set(word_vec)\n",
    "M = len(unique_word_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gibbs Sampling Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gibbs Sampling 실행 과정에서 사용하게 될 conditional distribution 에 대한 코드 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ p(z_{n}^{(d)}=t \\vert z_{-n}^{(d)},\\mathbf{w},\\alpha,\\beta) \\propto \\frac{ \\beta_{m}+\\sum_{d=1}^{D}\\sum_{n=1}^{N_{d}}I(w_{n}^{(d)}=m)I(z_{n}^{(d)}=t)}{ \\sum_{m=1}^{M}\\left(\\beta_{m}+\\sum_{d=1}^{D}\\sum_{n=1}^{N_{d}}I(w_{n}^{(d)}=m)I(z_{n}^{(d)}=t) \\right) } \\times \\left( \\alpha_{t}+ \\sum_{n=1}^{N_{d}} I(z_{n}^{(d)}=t) \\right) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampler_code(d, word, topic) :\n",
    "    \n",
    "    ((topic_word_counts[topic][word] + beta) / (topic_counts[topic] + M*beta)) * ((document_topic_counts[d][topic] + alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_weight(d, word, topic):\n",
    "    \"\"\"given a document and a word in that document,\n",
    "    return the weight for the kth topic\"\"\"\n",
    "    \n",
    "    def p_topic_given_document(topic, d, alpha=0.1):\n",
    "        \"\"\"the fraction of words in document _d_\n",
    "        that are assigned to _topic_ (plus some smoothing)\"\"\"\n",
    "        return ((document_topic_counts[d][topic] + alpha))\n",
    "\n",
    "    def p_word_given_topic(word, topic, beta=0.1):\n",
    "        \"\"\"the fraction of words assigned to _topic_\n",
    "        that equal _word_ (plus some smoothing)\"\"\"\n",
    "        return ((topic_word_counts[topic][word] + beta) / (topic_counts[topic] + M*beta))\n",
    "    \n",
    "    \n",
    "    return p_word_given_topic(word, topic) * p_topic_given_document(topic, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_new_topic(d, word):\n",
    "    \n",
    "    def sample_from(weights):\n",
    "        \"\"\"returns i with probability weights[i] / sum(weights)\"\"\"\n",
    "        total = sum(weights)\n",
    "        rnd = total * random.random() # uniform between 0 and total\n",
    "        for i, p in enumerate(weights):\n",
    "            rnd -= p # return the smallest i such that\n",
    "            if rnd <= 0: \n",
    "                return i # weights[0] + ... + weights[i] >= rnd\n",
    "        \n",
    "    return sample_from([topic_weight(d, word, topic) for topic in range(T)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 2, 1, 3, 3, 2, 0, 0],\n",
       " [0, 1, 3, 0, 2, 1],\n",
       " [1, 0, 2, 3, 1, 3, 0, 1, 0],\n",
       " [3, 0, 2, 3, 3, 2, 1],\n",
       " [3, 0, 2, 0, 1, 2],\n",
       " [2, 3, 1, 1, 3, 3],\n",
       " [2, 2, 0, 1, 2],\n",
       " [0, 1, 1, 2, 2, 3],\n",
       " [3, 2, 2, 2, 1, 3],\n",
       " [1, 3, 1, 3, 3, 3]]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topics = [[random.randrange(T) for word in document] for document in documents]\n",
    "document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1 \n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({3: 6, 1: 1, 2: 7, 0: 2}),\n",
       " Counter({3: 7, 2: 1, 0: 2, 1: 2}),\n",
       " Counter({3: 2, 1: 12, 0: 3, 2: 1}),\n",
       " Counter({2: 9, 3: 3, 0: 1, 1: 1}),\n",
       " Counter({1: 6, 2: 2, 0: 2, 3: 2}),\n",
       " Counter({3: 3, 0: 6, 2: 1, 1: 2}),\n",
       " Counter({0: 6, 1: 1, 2: 3, 3: 0}),\n",
       " Counter({1: 2, 3: 1, 0: 7, 2: 2}),\n",
       " Counter({3: 8, 0: 0, 2: 3, 1: 1}),\n",
       " Counter({0: 0, 3: 4, 2: 0, 1: 8})]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3000): # repetition\n",
    "    for d in range(D): # each documnet\n",
    "        for i, (word, topic) in enumerate(zip(documents[d],document_topics[d])):\n",
    "            \n",
    "            # gibbs sampling: 특정 하나의 topic assignment z를 제거하고 나머지들(-z)의 조건부 확률  \n",
    "            \n",
    "            # remove this word / topic from the counts\n",
    "            # so that it doesn't influence the weights\n",
    "            document_topic_counts[d][topic] -= 1 # 문서별 토픽 갯수\n",
    "            topic_word_counts[topic][word] -= 1 # 토픽별 단어 갯수\n",
    "            topic_counts[topic] -= 1 # 토픽별 카운트\n",
    "            document_lengths[d] -= 1 # 문서별 단어갯수\n",
    "            \n",
    "            # choose a new topic based on the weights\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "            \n",
    "            # and now add it back to the counts\n",
    "            document_topic_counts[d][new_topic] += 1 # 문서별 토픽 갯수\n",
    "            topic_word_counts[new_topic][word] += 1 # 토픽별 단어 갯수\n",
    "            topic_counts[new_topic] += 1 # 토픽별 카운트\n",
    "            document_lengths[d] += 1 # 문서별 단어갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Topic1','Topic2','Topic3','Topic4'], index=['Top'+str(i) for i in range(1,6)])\n",
    "\n",
    "for k, word_counts in enumerate(topic_word_counts):\n",
    "    for ix, (word, count) in enumerate(word_counts.most_common(6)): # 각 토픽별로 top 10 단어\n",
    "            df.loc['Top'+str(ix+1),'Topic'+str(k+1)] = word+'({})'.format(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Top1</th>\n",
       "      <td>5G(6)</td>\n",
       "      <td>바이오(4)</td>\n",
       "      <td>비이자(4)</td>\n",
       "      <td>반도체(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top2</th>\n",
       "      <td>통신(4)</td>\n",
       "      <td>수익성(4)</td>\n",
       "      <td>대출(4)</td>\n",
       "      <td>플랫폼(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top3</th>\n",
       "      <td>IPTV(4)</td>\n",
       "      <td>공정(4)</td>\n",
       "      <td>은행(4)</td>\n",
       "      <td>칩(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top4</th>\n",
       "      <td>이익(4)</td>\n",
       "      <td>코로나(4)</td>\n",
       "      <td>이자(3)</td>\n",
       "      <td>성장성(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top5</th>\n",
       "      <td>이동통신(2)</td>\n",
       "      <td>백신(4)</td>\n",
       "      <td>실적(2)</td>\n",
       "      <td>자율주행(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top6</th>\n",
       "      <td>스마트팩토리(2)</td>\n",
       "      <td>바이러스(4)</td>\n",
       "      <td>증권(2)</td>\n",
       "      <td>자동차(2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Topic1   Topic2  Topic3   Topic4\n",
       "Top1      5G(6)   바이오(4)  비이자(4)   반도체(4)\n",
       "Top2      통신(4)   수익성(4)   대출(4)   플랫폼(4)\n",
       "Top3    IPTV(4)    공정(4)   은행(4)     칩(4)\n",
       "Top4      이익(4)   코로나(4)   이자(3)   성장성(4)\n",
       "Top5    이동통신(2)    백신(4)   실적(2)  자율주행(4)\n",
       "Top6  스마트팩토리(2)  바이러스(4)   증권(2)   자동차(2)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
